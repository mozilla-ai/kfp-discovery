# Document to Podcast PoC

This is an adaptation of the [Document-to-Podcast Mozilla Blueprint](https://github.com/mozilla-ai/document-to-podcast)
to run on [Kubeflow Pipelines (KFP)](https://www.kubeflow.org/docs/components/pipelines/).

Flow steps:

- The [downloader](01.downloader) downloads a document giver a URL and stores it into an HTML file.
- The [transformer](02.transformer) processes the HTML document to extract the raw text.
- The [scriptwriter](03.scriptwriter) writes the podcast script.
- The [performer](04.perforer) generates the podcast.

All the images are public on Docker Hub, and you can find their names and tags in the [components](_components)
directory, as part of each KFP component.

There is also one Notebook: `pipeline.ipynb` creates the Kubeflow Pipeline YAML IR based on the aforementioned
components. You can submit the YAML IR either programmatically, using the Kubeflow Pipelines Python client, or upload
it through the Kubeflow Pipelines UI.

> For Mozilla.ai folks: there is a KFP instance running on CW that you can use.
> To port-forward the UI locally: `kubectl port-forward -n kubeflow svc/ml-pipeline-ui 8080:80` and visit
> [http://localhost:8080](http://localhost:8080).

To run the Notebooks locally, create a virtualenv, install the [requirements.txt](requirements.txt) file (there's only
one package there), open the Notebook (e.g., in VSCode) and select the appropriate kernel.

For your convenience, the repository contains a `document-to-podcast.yaml` file, which is the Kubeflow Pipeline IR
generated by the Notebook. This is not meant to be human-readable but you can use it to submit the pipeline directly to
your Kubeflow Pipelines instance.

## Read More

- [Kubeflow Pipelines](https://www.kubeflow.org/docs/components/pipelines/): A platform for building and deploying
  portable and scalable machine learning (ML) workflows using containers on Kubernetes-based systems.
- [Kubeflow Pipelines Components](https://www.kubeflow.org/docs/components/pipelines/concepts/component/): A pipeline
  component is self-contained set of code that performs one step in the ML workflow (pipeline), such as data
  preprocessing, data transformation, model training, and so on.
- [Kubeflow Pipelines Component Spec](https://www.kubeflow.org/docs/components/pipelines/reference/component-spec/):
  Describes the container component data model for Kubeflow Pipelines.
